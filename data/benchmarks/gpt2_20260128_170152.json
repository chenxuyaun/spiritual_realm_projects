{
  "report_name": "gpt2_20260128_170152",
  "model_name": "gpt2",
  "timestamp": "2026-01-28T17:01:52.851743",
  "system_info": {
    "platform": "Windows-10-10.0.26200-SP0",
    "python_version": "3.9.25",
    "torch_version": "2.8.0+cpu",
    "cuda": {
      "available": false,
      "version": ""
    },
    "gpu": {
      "name": "",
      "memory_gb": 0.0
    },
    "cpu": {
      "count": 18,
      "memory_gb": 31.574451446533203
    },
    "timestamp": "2026-01-28T17:01:52.863765"
  },
  "latency": [
    {
      "test_name": "latency_benchmark",
      "model_name": "gpt2",
      "timestamp": "2026-01-28T17:01:44.485390",
      "ttft": {
        "mean_ms": 1396.9747333333337,
        "std_ms": 244.80345451733947,
        "min_ms": 1188.270700000002,
        "max_ms": 1666.4349000000004,
        "p50_ms": 1336.2185999999988,
        "p95_ms": 1633.4132700000002,
        "p99_ms": 1659.8305740000003
      },
      "tokens_per_second": {
        "mean": 34.04948610981732,
        "std": 3.3765326757826664,
        "min": 31.53094068147188,
        "max": 37.886290512378814
      },
      "e2e_latency": {
        "mean_ms": 1470.7970666666672,
        "std_ms": 149.41866976336556,
        "min_ms": 1339.1297999999986,
        "max_ms": 1633.1902000000014
      },
      "config": {
        "warmup_runs": 1,
        "test_runs": 3,
        "input_length": 30,
        "output_length": 0
      }
    }
  ],
  "memory": [
    {
      "test_name": "inference_memory",
      "model_name": "gpt2",
      "timestamp": "2026-01-28T17:01:48.844095",
      "model_load": {
        "gpu_mb": 0.0,
        "cpu_mb": 0.0
      },
      "inference": {
        "gpu_peak_mb": 0.0,
        "gpu_delta_mb": 0.0,
        "cpu_peak_mb": 0.0,
        "cpu_delta_mb": 0.5703125
      },
      "kv_cache_mb": 0.0,
      "quantization": {
        "type": null,
        "memory_reduction_percent": 0.0
      },
      "config": {
        "input_length": 45,
        "output_length": 0,
        "gc_before_measure": true
      }
    }
  ],
  "throughput": [
    {
      "test_name": "single_throughput",
      "model_name": "gpt2",
      "timestamp": "2026-01-28T17:01:52.850732",
      "single": {
        "requests_per_second": 1.2825687492120208,
        "tokens_per_second": 38.47706247636063
      },
      "concurrent": {
        "requests_per_second": 0.0,
        "tokens_per_second": 0.0,
        "level": 1
      },
      "batch": {
        "requests_per_second": 0.0,
        "tokens_per_second": 0.0,
        "size": 1
      },
      "latency": {
        "mean_ms": 779.6831666666671,
        "p50_ms": 777.3097000000035,
        "p95_ms": 785.6383900000001,
        "p99_ms": 786.3787179999998
      },
      "summary": {
        "duration_seconds": 2.3390559000000017,
        "total_requests": 3,
        "total_tokens": 90,
        "failed_requests": 0
      }
    }
  ],
  "metadata": {
    "device": "cpu",
    "quick_mode": true,
    "warmup_runs": 1,
    "test_runs": 3
  }
}